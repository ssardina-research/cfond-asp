{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f61ecc3-8076-46de-ac6c-739412b48c6f",
   "metadata": {},
   "source": [
    "# Coverage Plots\n",
    "\n",
    "This notebook pre-processes the results obtained from Benchexec and plot it using seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2a61c4-d7a1-4b58-977d-c2bc468b61e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import dtale\n",
    "import re\n",
    "\n",
    "# sys.dont_write_bytecode = True  # prevent creation of .pyc files\n",
    "\n",
    "CSV_FOLDER = \"stats/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0cd1bd",
   "metadata": {},
   "source": [
    "## 1. Load data from CSV tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a27abb",
   "metadata": {},
   "source": [
    "Collect all CSV result files under `CSV_FOLDER` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c47cf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CSV files found in folder {CSV_FOLDER}:\")\n",
    "files = glob.glob(os.path.join(CSV_FOLDER, \"**\", \"benchmark-*.csv\"), recursive=True)\n",
    "\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0157c50e",
   "metadata": {},
   "source": [
    "Load all CSV data into a single dataframe. Note that each CSV file may include results for many _run sets_, with each having its own columns. \n",
    "\n",
    "Each row is the result of a _task_ in the experiment, and every run set has its columns stats for such task. We then need to reshape this and just have one set of columns and the run set be another new column.\n",
    "\n",
    "The first three lines contain header:\n",
    "\n",
    "1. First line contains the _tool_ used. It starts with `tool` followed by the name of the tool repeated multiple times (to match no. of columns).\n",
    "2. Second line contains the _runs_ of the experiment. It starts with `run set` and then sets of columns with the name of the runs.\n",
    "3. Third line contains the _stats_ column names repeated per run set. First column is for name of the task.\n",
    "\n",
    "An example with two runs `lpg` and `lpg_small`, using tool `PP-LPG`, is as follows:\n",
    "\n",
    "```\n",
    "tool\tPP-LPG \tPP-LPG \tPP-LPG \tPP-LPG \tPP-LPG \tPP-LPG \tPP-LPG \tPP-LPG \tPP-LPG \tPP-LPG \tPP-LPG \tPP-LPG \tPP-LPG \tPP-LPG \n",
    "run set\tlpg\tlpg\tlpg\tlpg\tlpg\tlpg\tlpg\tlpg_small\tlpg_small\tlpg_small\tlpg_small\tlpg_small\tlpg_small\tlpg_small\n",
    "/home/nitin/app/benchmarks/benchexe/tasks/\tstatus\tcputime (s)\twalltime (s)\tmemory (MB)\tpolicy_size\tsolve_time\ttranslation_time\tstatus\tcputime (s)\twalltime (s)\tmemory (MB)\tpolicy_size\tsolve_time\ttranslation_time\n",
    "AIJ_Barman_EIGHT50_1.yml\ttrue\t185.430462\t185.5002005007118\t295.952384\t4966\t185.0386784542352\t0.263661066070199\ttrue\t16.422719\t16.462604857981205\t273.047552\t4501\t16.02331303898245\t0.26572485268116\n",
    "AIJ_Barman_EIGHT50_10.yml\ttrue\t94.405856\t94.43696516938508\t288.591872\t5200\t93.96452420670539\t0.28180090803653\ttrue\t27.34709\t27.380704921670258\t276.148224\t3846\t26.93289530556649\t0.26796702668070793\n",
    "AIJ_Barman_EIGHT50_11.yml\tfalse\t1799.112512\t1799.4882240109146\t430.522368\t\t-1\t0.2723603779450059\ttrue\t550.644056\t550.7977258479223\t437.944320\t48991\t550.3052532738075\t0.2680810196325183\n",
    "AIJ_Barman_EIGHT50_12.yml\tfalse\t1799.168697\t1799.4754690360278\t457.166848\t\t-1\t0.2691544583067298\ttrue\t554.876223\t555.0061234645545\t416.649216\t52499\t554.5180832231417\t0.2642196826636791\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20ecb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "RENAME_COLS = {\"benchmarks/benchexe/tasks/\": \"id\", \"cputime (s)\": \"cputime\", \"walltime (s)\": \"walltime\", \"memory (MB)\": \"memory_mb\"}\n",
    "\n",
    "def get_meta_csv(file):\n",
    "    \"\"\"Given a benchexec CSV file, extract the runs (e.g., prp, prp_inv) and how many columns per run\"\"\"\n",
    "    with open(file, \"r\") as f:\n",
    "        # first line contains the tool used (repeated one per column needed); e.g.,  PP-FOND\n",
    "        tools_header = f.readline().split()[1:]\n",
    "        # second line contains the run/solvers used in the experiment (e.g., prp, prp_inv) and starts with \"run set\" to be ignored\n",
    "        runs_header = f.readline().split()[2:]\n",
    "\n",
    "    runs = set(runs_header)\n",
    "\n",
    "    no_cols = int(len(runs_header) / len(runs))\n",
    "\n",
    "    return runs, no_cols\n",
    "\n",
    "\n",
    "dfs = []\n",
    "for f in files:\n",
    "    runs, no_cols = get_meta_csv(f)\n",
    "    print(f\"Runs in file {f}: {runs} with {no_cols} stat columns\")\n",
    "\n",
    "    # go over each set of run columns (a csv file may contain many runs, each with the same columns)\n",
    "    for k, r in enumerate(list(runs)):\n",
    "        col_idx = [0] + list(range(k*no_cols + 1, k*no_cols + no_cols + 1))\n",
    "        print(f\"\\t Extracting run '{r}' in columns: {col_idx}\")\n",
    "\n",
    "        # read the CSV file from line 3+ (line 3 is header)\n",
    "        df = pd.read_csv(f, delimiter=\"\\t\", skiprows=2, usecols=col_idx)\n",
    "        df.rename(columns=lambda x: x.split('.')[0], inplace=True)\n",
    "\n",
    "        df.columns.values[0] = \"task\"\n",
    "        # df.rename(columns={df.columns[1]: \"task\"})\n",
    "\n",
    "        # populate column run with name of run-solver r\n",
    "        df.insert(1, 'run', r)\n",
    "        dfs.append(df)\n",
    "\n",
    "df_csv = pd.concat(dfs).reset_index(drop=True)\n",
    "\n",
    "df_csv.rename(columns=RENAME_COLS, inplace=True)\n",
    "\n",
    "# df.set_index(\"task\", inplace=True)\n",
    "df_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03a08eb",
   "metadata": {},
   "source": [
    "We next **enrich** the dataframe with derived columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78deaee6-26c0-47a9-adab-040f390599b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_benchmark_labels(task_name):\n",
    "    \"\"\"From the task description name (e.g., acrobatics_01.yml), extract the benchmark labels, like domain, instance\"\"\"\n",
    "    regex = r\"(.+)_([0-9]+)\\.yml\"\n",
    "\n",
    "    match = re.match(regex, task_name)\n",
    "    if match:\n",
    "        # print(match.groups())\n",
    "        domain = match.group(1)\n",
    "        instance = match.group(2)\n",
    "    else:\n",
    "        print(\"Problem extracting labels from task name\", task_name)\n",
    "    return domain, instance\n",
    "\n",
    "df = df_csv.copy()\n",
    "\n",
    "# 1 - split task name into domain and instances\n",
    "df[\"benchmark\"] = df.reset_index()[\"task\"].map(get_benchmark_labels).values\n",
    "df[\"domain\"] = df[\"benchmark\"].str.get(0)\n",
    "df[\"instance\"] = df[\"benchmark\"].str.get(1)\n",
    "df.drop(columns=[\"benchmark\"], inplace=True)\n",
    "\n",
    "# 2 - map status from benchexec to integers status\n",
    "map_status = {\n",
    "    \"true\": 1,\n",
    "    \"false\": 0,\n",
    "    \"OUT OF MEMORY (false)\": -2,\n",
    "    \"TIMEOUT (false)\": -1,\n",
    "    \"TIMEOUT (true)\": 1,\n",
    "}\n",
    "df[\"status2\"] = df[\"status\"].map(map_status)\n",
    "\n",
    "missing_mapping = df[df[\"status2\"].isnull()].shape[0]\n",
    "if missing_mapping > 0:\n",
    "    print(f\"WARNING: {missing_mapping} status values not mapped\")\n",
    "    print(df[df[\"status2\"].isnull()])\n",
    "\n",
    "df[\"status\"] = df[\"status2\"]\n",
    "df.drop(columns=[\"status2\"], inplace=True)\n",
    "\n",
    "# 3 - define Boolean column solved to flag if solved or not based on status\n",
    "df.insert(3, \"solved\", df[\"status\"].apply(lambda x: True if x == 1 else False))\n",
    "\n",
    "\n",
    "# 4 - extract solver from run name\n",
    "map_solver = {\n",
    "    \"prp.FOND\": \"prp\",\n",
    "    \"paladinus.FOND\": \"paladinus\"\n",
    "}\n",
    "df[\"solver\"] = df[\"run\"].map(map_solver)\n",
    "\n",
    "\n",
    "\n",
    "# sanity check status\n",
    "# df.query(\"status not in [-1,0,-2,1]\")\n",
    "# df.status = df.status.astype(int) # convert to int\n",
    "# df.loc[df.status == \"OUT OF MEMORY (false)\"]\n",
    "# df.loc[df.status == -1]\n",
    "\n",
    "# df.dtypes\n",
    "\n",
    "# note that status should be integer; if float it is bc there must be NaN value!\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5880343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver/runs found\n",
    "print(\"Solvers/run found:\", df['solver'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658fa16b-fcec-42b8-ba4e-d9668cae4c3d",
   "metadata": {},
   "source": [
    "Finally, save all results into a complete CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197f5437-6477-40b8-b6df-6dcde7bd36a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(CSV_FOLDER, \"results_benchexec_cfond.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec83105",
   "metadata": {},
   "source": [
    "## 2. Compute rich coverage table for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda058ab",
   "metadata": {},
   "source": [
    "First get the set of interest, by selecting domains and solvers to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfed477",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOLVERS = df[\"solver\"].unique()\n",
    "DOMAINS = df[\"domain\"].unique()\n",
    "\n",
    "print(\"Solvers selected:\", SOLVERS)\n",
    "print(\"Domains selected:\", DOMAINS)\n",
    "\n",
    "df_sel = df.loc[(df.solver.isin(SOLVERS)) & (df.domain.isin(DOMAINS))]\n",
    "\n",
    "df_sel = df\n",
    "\n",
    "df_sel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a91d05c",
   "metadata": {},
   "source": [
    "Count how MANY instances per domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8b3fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_index = ['domain']\n",
    "\n",
    "# count the number of each run per full_domain (e.g., how many lpg runs in Barman-EIGHT50)\n",
    "count_df = df_sel.groupby(by=selection_index)['solver'].value_counts()\n",
    "\n",
    "count_df = count_df.reset_index(name=\"count\")\n",
    "\n",
    "# # transofm the serie into a dataframe and value becomes percent\n",
    "# coverage_df = coverage_df.mul(100).round(0).rename('percent').reset_index()\n",
    "# coverage_df = coverage_df.loc[coverage_df.status].reset_index(drop=True)    # keep just the TRUE status (solved!)\n",
    "\n",
    "count_df\n",
    "# count_df.query(\"domain == 'miner' or domain == 'tireworld'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8070e2",
   "metadata": {},
   "source": [
    "Next calculate coverage for each solver run in each full domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01579519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coverage(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # columns to group-by\n",
    "    selection_index = [\"solver\", \"domain\"]\n",
    "\n",
    "    # count normalized (0-1) the number of grade after grouping for all the other values\n",
    "    coverage_df = df.groupby(by=selection_index)[\"solved\"].value_counts(normalize=True)\n",
    "\n",
    "    # transofm the serie into a dataframe and value becomes percent\n",
    "    coverage_df = coverage_df.mul(100).rename(\"percent\").reset_index()\n",
    "\n",
    "    # convert the rows that have 100% unsovable (False), to 0% solvable (True)\n",
    "    #   otherwise, there will be no True solvable for those cases!\n",
    "    mask_unsolvable = (~coverage_df.solved) & (coverage_df.percent == 100)\n",
    "    coverage_df.loc[mask_unsolvable, [\"solved\", \"percent\"]] = [True, 0]\n",
    "\n",
    "    # return the % of solvable stats\n",
    "    return coverage_df.loc[coverage_df.solved].round(\n",
    "        0\n",
    "    )\n",
    "\n",
    "coverage_df = compute_coverage(df_sel)\n",
    "coverage_df\n",
    "\n",
    "# SOME FILTERS\n",
    "# coverage_df.query(\"not solved and percent == 100\")\n",
    "# coverage_df.query(\"solved and percent == 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b3ecad",
   "metadata": {},
   "source": [
    "Compute the CPU time mean per domain/solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ca5020",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_index = [\"domain\", \"solver\"]\n",
    "\n",
    "# mean of cputime for SOLVED instances\n",
    "cputime_mean_df = df_sel.loc[df_sel.solved].groupby(by=selection_index)[\"cputime\"].mean().round(2)\n",
    "\n",
    "# mean of cputime for ALL instances\n",
    "# cputime_mean_df = df_sel.groupby(by=selection_index)[\"cputime\"].mean()\n",
    "\n",
    "cputime_mean_df = cputime_mean_df.reset_index(name=\"cputime_mean\")\n",
    "\n",
    "cputime_mean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe8e541",
   "metadata": {},
   "source": [
    "Join coverage table with count instances and cpu mean time tables, into a single one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b698cc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_df = coverage_df.merge(count_df)\n",
    "coverage_df = coverage_df.merge(cputime_mean_df)\n",
    "\n",
    "coverage_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747d8c99",
   "metadata": {},
   "source": [
    "## 3. Time and Coverage plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67b0118",
   "metadata": {},
   "source": [
    "Let's check the coverage in a particular domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a19d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "x = random.choice(coverage_df['domain'].unique())\n",
    "coverage_df.loc[coverage_df.domain == x]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a33a17",
   "metadata": {},
   "source": [
    "Some useful links to make nice charts:\n",
    "\n",
    "* [Changing plot style and color](https://s3.amazonaws.com/assets.datacamp.com/production/course_15192/slides/chapter4.pdf).\n",
    "* [Advanced Seaborn: Demystifying the Complex Plots!](https://levelup.gitconnected.com/advanced-seaborn-demystifying-the-complex-plots-537582977c8c#5965 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9053251c",
   "metadata": {},
   "source": [
    "OK this is the main code for drawing complex combined time-coverage charts across a full set benchmark (e.g., AIJ) as done with the R's script. \n",
    "\n",
    "For each full domain (e.g., Barman-EIGHT50), draw a plot showing scatter time performance across instances per solver/run AND coverage bars superimposed. This was Nitin's great graphs done originally in R for ECAI'23.\n",
    "\n",
    "In each subplot, the title shows the full domain with the number of instances run (e.g., \"Barman-EIGHT50 (20)\": 20 instances run for Barman-EIGHT50 full domain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736bc2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://seaborn.pydata.org/tutorial/aesthetics.html\n",
    "# https://seaborn.pydata.org/generated/seaborn.set_theme.html\n",
    "sns.set_theme()\n",
    "# sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "# DEFINE BOXES USED BELOW\n",
    "# box for the title of each subplot\n",
    "# https://matplotlib.org/stable/api/_as_gen/matplotlib.patches.FancyBboxPatch.html#matplotlib.patches.FancyBboxPatch\n",
    "bbox_title = dict(boxstyle=\"square\", fc=\"lightblue\", fill=True, color=\"r\")\n",
    "bbox_coverage = dict(boxstyle=\"round\", fc=\"0.9\", fill=True, color=\"r\")\n",
    "bbox_cputime = dict(boxstyle=None, fc=\"0.9\", fill=True, color=\"r\")\n",
    "\n",
    "####################################################################################\n",
    "## FIRST, produce one scatter subplot per domain with x=cputime and y=solver\n",
    "# https://seaborn.pydata.org/generated/seaborn.relplot.html#seaborn.relplot\n",
    "####################################################################################\n",
    "g = sns.relplot(\n",
    "    data=df_sel.query(\"solved\"),\n",
    "    kind=\"scatter\",\n",
    "    s=50,\n",
    "    x=\"cputime\",\n",
    "    y=\"solver\",\n",
    "    col=\"domain\",  # one subplot per domain\n",
    "    col_wrap=6,\n",
    "    height=4,\n",
    "    aspect=1.2,\n",
    ")\n",
    "\n",
    "# Let's set titles\n",
    "g.set_axis_labels(\"time\", \"solver\")\n",
    "g.set_titles(  #   most options are passed to text: https://matplotlib.org/stable/api/text_api.html\n",
    "    col_template=\"{col_name}\",\n",
    "    fontweight=\"demibold\",\n",
    "    ha=\"center\",\n",
    "    va=\"center\",\n",
    "    bbox=bbox_title,\n",
    ")\n",
    "g.figure.suptitle(\n",
    "    f\"Coverage Results\", ha=\"left\", va=\"top\", fontsize=\"xx-large\", y=1\n",
    ")  # https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.suptitle.html\n",
    "\n",
    "\n",
    "print(\"Finished building scattered plot of cputime. Next overlapping coverage bars...\")\n",
    "\n",
    "# get all the axes (subplots) of the FaceGrid\n",
    "axes = g.axes.flatten()\n",
    "sns.set_style(\"ticks\")  # just ticks, no grid from now on...\n",
    "\n",
    "####################################################################################\n",
    "# SECOND, super-impose cputime mean numbers per solver in each subplot in the grid\n",
    "#  #TODO: at this point I don't know to shift the number a bit up!\n",
    "####################################################################################\n",
    "for ax in axes:\n",
    "    domain = ax.get_title()\n",
    "    g_cpumean = sns.barplot(  # draw the bar of mean cputime per solver\n",
    "        data=coverage_df[coverage_df.domain.eq(domain)],\n",
    "        x=\"cputime_mean\",\n",
    "        y=\"solver\",\n",
    "        width=0.0001,\n",
    "        linewidth=2.5,\n",
    "        edgecolor=\".5\",\n",
    "        facecolor=(0, 0, 0, 0),\n",
    "        ax=ax,\n",
    "    )\n",
    "    g_cpumean.set(xlabel=None)\n",
    "\n",
    "    # add cpu mean number per solver, but a bit up to not clash with coverage bar!\n",
    "    # https://stackoverflow.com/questions/70693878/flexible-placement-of-labels-in-seaborn-barplots\n",
    "    for p in ax.patches:\n",
    "        perc = p.get_width()  # the label for the bar\n",
    "        x = p.get_width()\n",
    "        y = p.get_y() + p.get_height() / 2\n",
    "\n",
    "        ax.annotate(perc, (x * 1.1, y - 0.05), color=\"red\")\n",
    "\n",
    "    # this will add the cpu mean per solver, but will clash with the coverage bar!\n",
    "    # if len(ax.containers) > 0: # may not be no number!\n",
    "    #     ax.bar_label(  # set the mean number in the bar at the end (cannot shift tup!)\n",
    "    #         ax.containers[0],\n",
    "    #         fmt=\"%.2f\",\n",
    "    #         label_type=\"edge\",\n",
    "    #         padding=5,\n",
    "    #         fontweight=\"normal\",\n",
    "    #         rotation=\"horizontal\",\n",
    "    # )\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "## THIRD, super-impose the COVERAGE data in each subplot in the grid as done in\n",
    "#   https://stackoverflow.com/a/67612124\n",
    "#   we also rename the title of each subplot to include no of instances run\n",
    "#   we iterate on each axis and plot a barplot and add annotations/styles to it\n",
    "####################################################################################\n",
    "for ax in axes:\n",
    "    # redo title of subfigure to include number of instances between parenthesis, e.g., BARMAN-EIGHT50 (20)\n",
    "    domain = ax.get_title()\n",
    "    no_instances = coverage_df.loc[coverage_df.domain == ax.get_title()][\n",
    "        \"count\"\n",
    "    ].unique()[0]\n",
    "    ax.set_title(\n",
    "        f\"{domain} ({no_instances})\",\n",
    "        fontweight=\"demibold\",\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        bbox=bbox_title,\n",
    "    )\n",
    "\n",
    "    # add bar of coverage % for each run/solver\n",
    "    ax2 = (\n",
    "        ax.twiny()\n",
    "    )  # get a twin y-axies https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.twinx.html\n",
    "    g2 = sns.barplot(\n",
    "        data=coverage_df[coverage_df.domain.eq(domain)],\n",
    "        x=\"percent\",\n",
    "        y=\"solver\",\n",
    "        width=0.0001,\n",
    "        linewidth=1.5,\n",
    "        edgecolor=\".5\",\n",
    "        facecolor=(0, 0, 0, 0),\n",
    "        ax=ax2,\n",
    "    )\n",
    "    g2.set_xlabel(\"coverage\", x=0, ha=\"left\")\n",
    "    g2.set_xlim([0, 100])\n",
    "\n",
    "    # add box with % of coverage at the end of the barline, if any!\n",
    "    if len(ax2.containers) > 0:\n",
    "        ax2.bar_label(\n",
    "            ax2.containers[0],\n",
    "            label_type=\"edge\",\n",
    "            padding=-5,\n",
    "            fontweight=\"normal\",\n",
    "            rotation=\"horizontal\",\n",
    "            bbox=bbox_coverage,\n",
    "        )\n",
    "\n",
    "# set the axis labels for the whole plot\n",
    "g.set_axis_labels(\"time\", \"solver\")\n",
    "\n",
    "# axes[0].legend().remove()\n",
    "# g.set_axis_labels(x_var=None, y_var=None, clear_inner=True)\n",
    "sns.despine(left=True, bottom=True)  # no spines at all\n",
    "\n",
    "# Save it later, not here.\n",
    "# plt.savefig(os.path.join(CSV_FOLDER, f\"{SET}_plot.png\"))\n",
    "\n",
    "plt.tight_layout()  # at the end adjust so everything fits tight but well\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e119f461",
   "metadata": {},
   "source": [
    "Double check some of the numbers there to make sure they match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ff5a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sel.query(\"solver == 'prp' and domain == 'islands' and solved\")['cputime'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ae145c",
   "metadata": {},
   "source": [
    "Save graph in a PNG file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb904c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.savefig(os.path.join(CSV_FOLDER, f\"{SET}_plot.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb16c3d0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf3940d3",
   "metadata": {},
   "source": [
    "## 4. Coverage Analysis\n",
    "\n",
    "We now generate **coverage** tables, as they often apper in papers. Basically we compute per benchmark set, domain, and APP type sub-domain, and each solver-run:\n",
    "\n",
    "- **Coverage:** % of solved instances solved by the solver-run; and\n",
    "- **Stat metrics:** mean on time, memory usage, and policy size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69da6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(CSV_FOLDER, \"results_benchexec_cfond.csv\"))\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19787b9",
   "metadata": {},
   "source": [
    "Calculate % ratio per set/domain/sub_domain/run-solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0559695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df.groupby([\"domain\", \"solver\"])\n",
    "\n",
    "#   df_grouped.sum()[[\"solved\"]] = sum all the True instances (sum over bool = number of True)\n",
    "#   df_grouped.count()[[\"solved\"]] = number of rows in solved column (includes True and Talse values)\n",
    "df_coverage = df_grouped.sum()[[\"solved\"]] / df_grouped.count()[[\"solved\"]]\n",
    "df_coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63285049",
   "metadata": {},
   "source": [
    "Calculate mean metric (for CPU time, memory, and policy size) across the solved instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf0dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"domain\", \"solver\", \"cputime\", \"memory_mb\", \"policy_size\"]\n",
    "df_solved = df.query(\"solved == True\")[columns]\n",
    "\n",
    "df_solved_grouped = df_solved.groupby([\"domain\", \"solver\"])\n",
    "df_metrics = df_solved_grouped.mean()\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e256f8",
   "metadata": {},
   "source": [
    "Put together **Coverage** and **Metrics** tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc03c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = {\n",
    "    \"solved\": \"cov\",\n",
    "    \"cputime\": \"time\",\n",
    "    \"memory_mb\": \"mem\",\n",
    "    \"policy_size\": \"size\",\n",
    "}\n",
    "\n",
    "df_stats = df_coverage.join(df_metrics, how=\"inner\")\n",
    "df_stats.rename(columns=column_names, inplace=True)\n",
    "\n",
    "df_stats = df_stats.reset_index()\n",
    "\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c66453",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_pivot = df_stats.pivot(\n",
    "    index=[\"domain\"],\n",
    "    values=[\"cov\", \"time\", \"mem\", \"size\"],\n",
    "    columns=\"solver\",\n",
    ")\n",
    "df_stats_pivot.reset_index(\n",
    "    inplace=True\n",
    ")  # unfold multi-index into columns (create integer index)\n",
    "df_stats_pivot.columns = [\n",
    "    \"_\".join(tup).rstrip(\"_\") for tup in df_stats_pivot.columns.values\n",
    "]\n",
    "\n",
    "# flat index, but multi-column: 1. coverage / time / policy size and 2. each solver/run\n",
    "df_stats_pivot = df_stats_pivot.round(2)\n",
    "\n",
    "df_stats_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086112ae",
   "metadata": {},
   "source": [
    "Save it to the file, this can be used in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc9053",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_pivot.to_csv(os.path.join(CSV_FOLDER, \"results_benchexec_cfond_paper.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
