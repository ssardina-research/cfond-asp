{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f61ecc3-8076-46de-ac6c-739412b48c6f",
   "metadata": {},
   "source": [
    "# Analysis Notebook for BenchExec Experiments\n",
    "\n",
    "This notebook pre-processes the results obtained from Benchexec and plot it using seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2a61c4-d7a1-4b58-977d-c2bc468b61e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "# sys.dont_write_bytecode = True  # prevent creation of .pyc files\n",
    "\n",
    "CSV_FOLDER = \"stats/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0cd1bd",
   "metadata": {},
   "source": [
    "## 1. Load data from CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a27abb",
   "metadata": {},
   "source": [
    "Collect all CSV result files under `CSV_FOLDER` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c47cf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CSV files found in folder {CSV_FOLDER}:\")\n",
    "files = glob.glob(os.path.join(CSV_FOLDER, \"results.*.csv\"))\n",
    "\n",
    "# optional filter\n",
    "# files = [f for f in files if \"PALA\" not in f]\n",
    "\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20ecb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for f in files:\n",
    "    df = pd.read_csv(f, delimiter=\",\", skiprows=0)\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs).reset_index(drop=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03a08eb",
   "metadata": {},
   "source": [
    "Add bolean `solved` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78deaee6-26c0-47a9-adab-040f390599b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, define Boolean column solved to flag if solved or not based on status\n",
    "df.insert(3, \"solved\", df['status'].apply(lambda x: True if x == 1 else False))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5880343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver/runs found\n",
    "print(\"Solvers/run found:\", df['solver'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658fa16b-fcec-42b8-ba4e-d9668cae4c3d",
   "metadata": {},
   "source": [
    "Finally, save all results into a complete CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197f5437-6477-40b8-b6df-6dcde7bd36a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(os.path.join(CSV_FOLDER, \"results_all.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d5f5b",
   "metadata": {},
   "source": [
    "## 2. Analysis example for set benchmark (e.g., AIJ, IJCAI, SOCS, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60a29de",
   "metadata": {},
   "source": [
    "First select subset of interest (set and solver runs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1792cd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOLVERS = df[\"solver\"].unique()\n",
    "DOMAINS = df[\"domain\"].unique()\n",
    "\n",
    "print(\"Solvers selected:\", SOLVERS)\n",
    "print(\"Domains selected:\", DOMAINS)\n",
    "\n",
    "df_sel = df.loc[(df.solver.isin(SOLVERS)) & (df.domain.isin(DOMAINS))]\n",
    "\n",
    "df_sel = df\n",
    "\n",
    "df_sel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6474984",
   "metadata": {},
   "source": [
    "Let's do a quick scattered plot for each class domain between solver run and cputime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e6034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(data=df_sel, kind=\"scatter\", x='solver',  y=\"time\", col=\"domain\",  col_wrap=6, height=3.5, aspect=1, legend=True)\n",
    "\n",
    "g.set_titles(template='{col_name}',y=1)\n",
    "\n",
    "# rotate x-labels\n",
    "x_labels = g.axes[-1].get_xticklabels() # get x labels of last plot in grid (must have the labels!)\n",
    "g.set_xticklabels(labels=x_labels, rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec83105",
   "metadata": {},
   "source": [
    "## 3. Time-coverage charts for ALL full domains in selected set benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a91d05c",
   "metadata": {},
   "source": [
    "Count how MANY instances per full domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8b3fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_index = ['domain']\n",
    "\n",
    "# count the number of each run per full_domain (e.g., how many PRP runs in Barman)\n",
    "count_df = df_sel.groupby(by=selection_index)['solver'].value_counts()\n",
    "\n",
    "count_df = count_df.reset_index(name='count')\n",
    "\n",
    "count_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8070e2",
   "metadata": {},
   "source": [
    "Next calculate coverage for each solver run in each full domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01579519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coverage(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # columns to group-by\n",
    "    selection_index = [\"solver\", \"domain\"]\n",
    "\n",
    "    # count normalized (0-1) the number of grade after grouping for all the other values\n",
    "    coverage_df = df.groupby(by=selection_index)[\"solved\"].value_counts(normalize=True)\n",
    "\n",
    "    # transofm the serie into a dataframe and value becomes percent\n",
    "    coverage_df = coverage_df.mul(100).rename(\"percent\").reset_index()\n",
    "\n",
    "    # convert the rows that have 100% unsovable (False), to 0% solvable (True)\n",
    "    #   otherwise, there will be no True solvable for those cases!\n",
    "    mask_unsolvable = (~coverage_df.solved) & (coverage_df.percent == 100)\n",
    "    coverage_df.loc[mask_unsolvable, [\"solved\", \"percent\"]] = [True, 0]\n",
    "\n",
    "    # return the % of solvable stats\n",
    "    return coverage_df.loc[coverage_df.solved].round(0)\n",
    "\n",
    "# # merge with count of instances per full domain\n",
    "coverage_df = compute_coverage(df_sel)\n",
    "coverage_df = coverage_df.merge(count_df)\n",
    "coverage_df\n",
    "\n",
    "# SOME FILTERS\n",
    "# coverage_df.query(\"not solved and percent == 100\")\n",
    "# coverage_df.query(\"solved and percent == 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67b0118",
   "metadata": {},
   "source": [
    "Let's check the coverage in a particular full domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a19d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "x = random.choice(coverage_df['domain'].unique())\n",
    "coverage_df.loc[coverage_df.domain == x]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a33a17",
   "metadata": {},
   "source": [
    "Some useful links to make nice charts:\n",
    "\n",
    "* [Changing plot style and color](https://s3.amazonaws.com/assets.datacamp.com/production/course_15192/slides/chapter4.pdf).\n",
    "* [Advanced Seaborn: Demystifying the Complex Plots!](https://levelup.gitconnected.com/advanced-seaborn-demystifying-the-complex-plots-537582977c8c#5965 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9053251c",
   "metadata": {},
   "source": [
    "OK this is the main code for drawing complex combined time-coverage charts across a full set benchmark (e.g., AIJ) as done with the R's script. \n",
    "\n",
    "For each full domain (e.g., Barman-EIGHT50), draw a plot showing scatter time performance across instances per solver/run AND coverage bars superimposed. This was Nitin's great graphs done originally in R for ECAI'23.\n",
    "\n",
    "In each subplot, the title shows the full domain with the number of instances run (e.g., \"Barman-EIGHT50 (20)\": 20 instances run for Barman-EIGHT50 full domain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736bc2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://seaborn.pydata.org/tutorial/aesthetics.html\n",
    "# https://seaborn.pydata.org/generated/seaborn.set_theme.html\n",
    "sns.set_theme()\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# FIRST graph for cputime per solver\n",
    "# sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "# box for the title of each subplot\n",
    "# https://matplotlib.org/stable/api/_as_gen/matplotlib.patches.FancyBboxPatch.html#matplotlib.patches.FancyBboxPatch\n",
    "bbox1 = dict(boxstyle=\"square\", fc=\"lightblue\", fill=True, color='r')\n",
    "bbox2 = dict(boxstyle=\"round\", fc=\"0.9\", fill=True, color='r')\n",
    "\n",
    "\n",
    "## FIRST, we do a scatter plot for each full domain showing cputime for each solved instance across each solver/run\n",
    "# https://seaborn.pydata.org/generated/seaborn.relplot.html#seaborn.relplot\n",
    "g = sns.relplot(data=df_sel.query('solved'), kind=\"scatter\", x='time', y='solver', col=\"domain\", col_wrap=6, height=4, aspect=1.2)\n",
    "g.set_axis_labels(\"time\", \"solver\")\n",
    "# Let's configure the title of each subplot\n",
    "#   most options are passed to text: https://matplotlib.org/stable/api/text_api.html\n",
    "g.set_titles(col_template='{col_name}', fontweight=\"demibold\",  ha='center', va='center', bbox=bbox1)\n",
    "\n",
    "# get the whole figure title: XXX Benchmark\n",
    "g.figure.suptitle(\n",
    "    f\"Coverage Results\", ha=\"left\", va=\"top\", fontsize=\"xx-large\", y=1\n",
    ")  # https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.suptitle.html\n",
    "\n",
    "\n",
    "print(\"Finished building scattered plot of cputime. Next overlapping coverage bars...\")\n",
    "\n",
    "# get all the axes (subplots) of the FaceGrid\n",
    "axes = g.axes.flatten()\n",
    "\n",
    "## SECOND, super-impose the COVERAGE data in each subplot in the grid as done in https://stackoverflow.com/a/67612124\n",
    "#   we also rename the title of each subplot to include no of instances run\n",
    "#   we iterate on each axis and plot a barplot and add annotations/styles to it\n",
    "sns.set_style(\"ticks\")  # just ticks, no grid\n",
    "for ax in axes:\n",
    "    # full_domian = ax.get_title().split(' = ')[1]\n",
    "    domain = ax.get_title()\n",
    "\n",
    "    # redo title of subfigure to include number of instances between parenthesis, e.g., BARMAN-EIGHT50 (20)\n",
    "    no_instances = coverage_df.loc[coverage_df.domain == ax.get_title()]['count'].unique()[0]\n",
    "    ax.set_title(f\"{domain} ({no_instances})\", fontweight=\"demibold\",  ha='center', va='center', bbox=bbox1)\n",
    "\n",
    "    # add bar of coverage % for each run/solver\n",
    "    ax2 = ax.twiny()    # get a twin y-axies https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.twinx.html\n",
    "    g2 = sns.barplot(data=coverage_df[coverage_df.domain.eq(domain)], x=\"percent\", y=\"solver\", width=0.0001, linewidth=2.5, edgecolor=\".5\", facecolor=(0, 0, 0, 0), ax=ax2)\n",
    "    g2.set_xlabel('coverage', x=0, ha=\"left\")\n",
    "    g2.set_xlim([0, 100])\n",
    "\n",
    "    # add box with % of coverage at the end of the barline\n",
    "    if len(ax2.containers) > 0 :\n",
    "        ax2.bar_label(ax2.containers[0], label_type='edge', padding=-5, fontweight='normal', rotation=\"horizontal\", bbox=bbox2)\n",
    "\n",
    "\n",
    "# axes[0].legend().remove()\n",
    "# g.set_axis_labels(x_var=None, y_var=None, clear_inner=True)\n",
    "sns.despine(left=True, bottom=True) # no spines at all\n",
    "\n",
    "# Save it later, not here.\n",
    "# plt.savefig(os.path.join(CSV_FOLDER, f\"{SET}_plot.png\"))\n",
    "\n",
    "plt.tight_layout()  # at the end adjust so everything fits tight but well\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ae145c",
   "metadata": {},
   "source": [
    "Save graph in a PNG file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb904c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.savefig(os.path.join(CSV_FOLDER, f\"coverage_plot.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb16c3d0",
   "metadata": {},
   "source": [
    "## 4. Coverage Analysis\n",
    "\n",
    "We now generate **coverage** tables, as they often apper in papers. Basically we compute per benchmark set, domain, and APP type sub-domain, and each solver-run:\n",
    "\n",
    "- **Coverage:** % of solved instances solved by the solver-run; and\n",
    "- **Stat metrics:** mean on time, memory usage, and policy size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69da6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(os.path.join(CSV_FOLDER,\"results_all.csv\"))\n",
    "df = df_sel\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19787b9",
   "metadata": {},
   "source": [
    "Calculate % ratio per set/domain/sub_domain/run-solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0559695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df.groupby([\"domain\", \"solver\"])\n",
    "\n",
    "#   df_grouped.sum()[[\"solved\"]] = sum all the True instances (sum over bool = number of True)\n",
    "#   df_grouped.count()[[\"solved\"]] = number of rows in solved column (includes True and Talse values)\n",
    "df_coverage = df_grouped.sum()[[\"solved\"]] / df_grouped.count()[[\"solved\"]]\n",
    "df_coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63285049",
   "metadata": {},
   "source": [
    "Calculate mean metric (for CPU time, memory, and policy size) across the solved instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf0dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"domain\", \"solver\", \"time\"]\n",
    "df_solved = df.query(\"solved == True\")[columns]\n",
    "\n",
    "df_solved_grouped = df_solved.groupby([\"domain\", \"solver\"])\n",
    "df_metrics = df_solved_grouped.mean()\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e256f8",
   "metadata": {},
   "source": [
    "Put together **Coverage** and **Metrics** tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc03c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = {\n",
    "    \"solved\": \"cov\",\n",
    "    \"time\": \"time\"\n",
    "    # \"memory_mb\": \"mem\",\n",
    "    # \"policy_size\": \"size\",\n",
    "}\n",
    "\n",
    "df_stats = df_coverage.join(df_metrics, how=\"inner\")\n",
    "df_stats.rename(columns=column_names, inplace=True)\n",
    "\n",
    "df_stats = df_stats.reset_index()\n",
    "# df_stats.insert(0, \"set\", df_stats.pop(\"set\"))\n",
    "\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c66453",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_pivot = df_stats.pivot(\n",
    "    index=[\"domain\"],\n",
    "    values=[\"cov\", \"time\"],\n",
    "    columns=\"solver\",\n",
    ")\n",
    "df_stats_pivot.reset_index(\n",
    "    inplace=True\n",
    ")  # unfold multi-index into columns (create integer index)\n",
    "df_stats_pivot.columns = [\n",
    "    \"_\".join(tup).rstrip(\"_\") for tup in df_stats_pivot.columns.values\n",
    "]\n",
    "\n",
    "# flat index, but multi-column: 1. coverage / time / policy size and 2. each solver/run\n",
    "df_stats_pivot = df_stats_pivot.round(2)\n",
    "\n",
    "df_stats_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086112ae",
   "metadata": {},
   "source": [
    "Save it to the file, this can be used in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc9053",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_pivot.to_csv(os.path.join(CSV_FOLDER, \"coverage_stats.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
